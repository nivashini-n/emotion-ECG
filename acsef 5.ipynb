{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YAAD Dataset Import and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import plotly.express as px\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess and HRV extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from acsef_hrv_extraction import hrv_extraction\n",
    "\n",
    "hrv_df = pd.DataFrame()\n",
    "\n",
    "dir = \"/Users/nivinattudurai/Downloads/YAAD 1/ECG_GSR_Emotions/Raw Data/Multimodal/ECG/\"\n",
    "\n",
    "def by_numbers(s): \n",
    "    return int(''.join(char for char in s if char.isdigit()))\n",
    "\n",
    "files = sorted(os.listdir(dir), key=by_numbers)\n",
    "\n",
    "for filename in files:\n",
    "    hrv = hrv_extraction(dir+filename)\n",
    "    hrv_df = pd.concat([hrv_df, hrv])\n",
    "    print(hrv_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21,7))\n",
    "sns.heatmap(hrv_df.isna().values, cmap=\"crest\", xticklabels=hrv_df.columns)\n",
    "plt.title('NaN heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop 100% missing value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns with missing data (null values) in train daaset =  16\n",
      "\n",
      "Missing data stats :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing count</th>\n",
       "      <th>Missing percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HRV_SDANN1</th>\n",
       "      <td>252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_SDNNI1</th>\n",
       "      <td>252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_SDANN2</th>\n",
       "      <td>252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_SDNNI2</th>\n",
       "      <td>252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_SDANN5</th>\n",
       "      <td>252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_SDNNI5</th>\n",
       "      <td>252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_ULF</th>\n",
       "      <td>252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_VLF</th>\n",
       "      <td>252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_LF</th>\n",
       "      <td>252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_LFHF</th>\n",
       "      <td>252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_LFn</th>\n",
       "      <td>252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_MSEn</th>\n",
       "      <td>207</td>\n",
       "      <td>0.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_CMSEn</th>\n",
       "      <td>207</td>\n",
       "      <td>0.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_RCMSEn</th>\n",
       "      <td>207</td>\n",
       "      <td>0.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_VHF</th>\n",
       "      <td>142</td>\n",
       "      <td>0.563492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRV_HFD</th>\n",
       "      <td>5</td>\n",
       "      <td>0.019841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Missing count  Missing percentage\n",
       "HRV_SDANN1            252            1.000000\n",
       "HRV_SDNNI1            252            1.000000\n",
       "HRV_SDANN2            252            1.000000\n",
       "HRV_SDNNI2            252            1.000000\n",
       "HRV_SDANN5            252            1.000000\n",
       "HRV_SDNNI5            252            1.000000\n",
       "HRV_ULF               252            1.000000\n",
       "HRV_VLF               252            1.000000\n",
       "HRV_LF                252            1.000000\n",
       "HRV_LFHF              252            1.000000\n",
       "HRV_LFn               252            1.000000\n",
       "HRV_MSEn              207            0.821429\n",
       "HRV_CMSEn             207            0.821429\n",
       "HRV_RCMSEn            207            0.821429\n",
       "HRV_VHF               142            0.563492\n",
       "HRV_HFD                 5            0.019841"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_count = hrv_df.isna().sum()\n",
    "missing_df=(pd.concat([missing_count.rename('Missing count'),\n",
    "                      missing_count.div(len(hrv_df)).rename('Missing percentage')], axis=1)).loc[missing_count.ne(0)]\n",
    "\n",
    "print(\"Number of columns with missing data (null values) in train daaset = \", len(missing_df) )\n",
    "print()\n",
    "print(\"Missing data stats :\")\n",
    "missing_df.sort_values(by=['Missing percentage'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['HRV_SDANN1', 'HRV_SDNNI1', 'HRV_SDANN2', 'HRV_SDNNI2', 'HRV_SDANN5', 'HRV_SDNNI5', 'HRV_ULF', 'HRV_VLF', 'HRV_LF', 'HRV_LFHF', 'HRV_LFn']\n",
    "hrv_df.drop(drop_cols, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing value columns with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_num_cols = set(list(hrv_df.select_dtypes('number').columns))\n",
    "replace_cols = set(list(missing_df.index)) - set(drop_cols)\n",
    "replace_num_cols = list(all_num_cols.intersection(replace_cols))\n",
    "\n",
    "\n",
    "replace_vals_hrv = {}\n",
    "for col in replace_num_cols:\n",
    "    replace_vals_hrv[col] = hrv_df[col].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv_df = hrv_df.fillna(value=replace_vals_hrv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data \n",
    "scaler = MinMaxScaler()\n",
    "hrv_df[replace_num_cols] = scaler.fit_transform(hrv_df[replace_num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Label Matrix and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"/Users/nivinattudurai/Downloads/YAAD 1/ECG_GSR_Emotions/Self-Annotation Labels/Self-annotation Multimodal copy.csv\")\n",
    "df3 = pd.DataFrame(df2)\n",
    "\n",
    "replacements = {'VeryHigh': 5, 'High': 4, 'Moderate': 3, 'Low': 2, 'VeryLow': 1}\n",
    "\n",
    "\n",
    "df3[[\"Happy\", \"Sad\", \"Fear\", \"Anger\", \"Neutral\", \"Disgust\", \"Surprised\"]] = df3[[\"Happy\", \"Sad\", \"Fear\", \"Anger\", \"Neutral\", \"Disgust\", \"Surprised\"]].replace(replacements)\n",
    "df3\n",
    "\n",
    "r1 = df3[[\"Happy\", \"Sad\", \"Fear\", \"Anger\", \"Neutral\", \"Disgust\", \"Surprised\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r1\n",
    "r2.loc[r2[\"Happy\"] >= 3, 'Happy'] = 0\n",
    "r2.loc[r2[\"Happy\"] != 0, 'Happy'] = -1\n",
    "r2.loc[r2[\"Sad\"] >= 3, 'Sad'] = 0\n",
    "r2.loc[r2[\"Sad\"] != 0, 'Sad'] = -1\n",
    "r2.loc[r2[\"Fear\"] >= 3, 'Fear'] = 0\n",
    "r2.loc[r2[\"Fear\"] != 0, 'Fear'] = -1\n",
    "r2.loc[r2[\"Anger\"] >= 3, 'Anger'] = 0\n",
    "r2.loc[r2[\"Anger\"] != 0, 'Anger'] = -1\n",
    "r2.loc[r2[\"Neutral\"] >= 3, 'Neutral'] = 0\n",
    "r2.loc[r2[\"Neutral\"] != 0, 'Neutral'] = -1\n",
    "r2.loc[r2[\"Disgust\"] >= 3, 'Disgust'] = 0\n",
    "r2.loc[r2[\"Disgust\"] != 0, 'Disgust'] = -1\n",
    "r2.loc[r2[\"Surprised\"] >= 3, 'Surprised'] = 0\n",
    "r2.loc[r2[\"Surprised\"] != 0, 'Surprised'] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = hrv_df\n",
    "y = r2\n",
    "\n",
    "X = X.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "#X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.80, random_state=1,stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca_X = pca.fit_transform(X)\n",
    "pca_X = pd.DataFrame(pca_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_indices = list(range(len(X)))\n",
    "#train_indices, test_indices = train_test_split(all_indices, test_size=0.2)\n",
    "\n",
    "#X_train = array(pca_X.iloc[train_indices])\n",
    "#X_test = array(pca_X.iloc[test_indices])\n",
    "#Y_train = array(y.iloc[train_indices, :])\n",
    "#Y_test = array(y.iloc[test_indices, :])\n",
    "\n",
    "#X_test = X_test.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forest = RandomForestClassifier(random_state=1)\n",
    "#multi_target_forest = MultiOutputClassifier(forest, n_jobs=2)\n",
    "#model = multi_target_forest.fit(X_train, Y_train)\n",
    "#preds1 = model.predict(X_test)\n",
    "#model.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 14:59:07.881887: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(5, input_dim=69, activation='relu'))\n",
    " model.add(Dense(2, activation='relu'))\n",
    " model.add(Dense(7, activation='softmax'))\n",
    " # Compile model\n",
    " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = array(pca_X)\n",
    "y_a = array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = LabelEncoder()\n",
    "#encoder.fit(y_a)\n",
    "#encoded_Y = encoder.transform(y_a)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "#dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nivinattudurai/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 15:01:43.638291: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 74.40% (38.75%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = cross_val_score(estimator, X_a, y_a, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
